{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset preparations - 03/01/2021 \n",
    "\n",
    "The dataset must be prepared according to the input requirements to the model. the model should then be designed to take spectrograms with dimensions $16*128$.\n",
    "\n",
    "several steps should be taken,\n",
    "\n",
    "we would like the samples from each class to be stored in separate folders, it is worth considering what folder structure should be used.\n",
    "\n",
    "each data sample should be converted into a spectrogram and stored in a json file. \n",
    "\n",
    "This makes things easier down the line as when training we can just read the json file for the spectrograms. this is much faster than if it is required to read the audio, convert them into a spectrogram during training. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/synthetic/various_sounds/\n"
     ]
    }
   ],
   "source": [
    "import librosa \n",
    "import os \n",
    "import json \n",
    "from tqdm import tqdm \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def prepare_dataset(n_mfcc = 128,n_mels= 128, hop_length= 520, n_fft =2048, train = True, f_max = 1024, mode = 0):\n",
    "    modes = [\"train\",\"test\",\"various\"]\n",
    "    \n",
    "    mode_string = modes[mode]\n",
    "    dataset_path = \"./data/synthetic/\"+mode_string+\"_sounds/\"\n",
    "    json_path = \"./data/synthetic/\"+mode_string+\"_data.json\"\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    data = {\n",
    "        \"mappings\" : [],\n",
    "        \"labels\" : [],\n",
    "        \"data\":[],\n",
    "        \"files\":[]\n",
    "    }\n",
    "    \n",
    "    print(dataset_path)\n",
    "\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
    "        category = dirpath.split(\"/\")[-1]\n",
    "        data[\"mappings\"].append(category)\n",
    "        \n",
    "        for j in range(len(filenames)):\n",
    "            f = filenames[j]\n",
    "            fpath = os.path.join(dirpath,f)\n",
    "            audio, sr = librosa.load(fpath)\n",
    "            \n",
    "            mel = librosa.feature.melspectrogram(audio, n_mels = n_mels, hop_length = hop_length, n_fft = n_fft, fmax = f_max)\n",
    "            data[\"labels\"].append(i-1)\n",
    "            data[\"data\"].append([librosa.power_to_db(mel).tolist()])\n",
    "            data[\"files\"].append(fpath)\n",
    "        if train: \n",
    "            if i ==1:\n",
    "                break \n",
    "                \n",
    "    \n",
    "    with open(json_path,\"w\") as fp: \n",
    "        json.dump(data, fp, indent=4)\n",
    "        \n",
    "    return \n",
    "\n",
    "prepare_dataset(mode =2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
