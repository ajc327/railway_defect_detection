{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch - I familiarise with Pytorch to learn the skills required to build the netowrks\n",
    "\n",
    "A tensor is a number, vector, matrix or any n-d array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], device='cuda:0', requires_grad=True)\n",
      "torch.Size([2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "my_tensor = torch.tensor([[1,2,3],[4,5,6]],dtype = torch.float32,\n",
    "                        device = device,requires_grad = True)\n",
    "print(my_tensor)\n",
    "print(my_tensor.shape)\n",
    "\n",
    "x = torch.empty(size = (3,3))\n",
    "x = torch.zeros(())\n",
    "x = torch.rand((3,3))\n",
    "x = torch.ones((3,3))\n",
    "x = torch.eye((3))\n",
    "x = torch.arange(0,5,1)\n",
    "x = torch.linspace(0,5,6)\n",
    "x = torch.empty(size=(1,5)).normal_(mean=0,std=1)\n",
    "x = torch.empty(size =(1,5)).uniform_(0,1)\n",
    "x = torch.diag(torch.ones(3))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False,  True,  True,  True])\n",
      "tensor([0, 1, 2, 3], dtype=torch.int16)\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([0., 1., 2., 3.], dtype=torch.float16)\n",
      "tensor([0., 1., 2., 3.])\n",
      "tensor([0., 1., 2., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# initialize and convert tensors to other types (int, float, double)\n",
    "tensor = torch.arange(4)\n",
    "print(tensor.bool())\n",
    "print(tensor.short())\n",
    "print(tensor.long())\n",
    "print(tensor.half())  # I dont have such a GPU so its not posible to use this \n",
    "print(tensor.float())  # Super used \n",
    "print(tensor.double())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Array to tensor conversion and vice versa \n",
    "import numpy as np \n",
    "np_array = np.zeros((5,5))\n",
    "tensor = torch.from_numpy(np_array)\n",
    "print(tensor)\n",
    "np_array = tensor.numpy()\n",
    "print(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 8., 10., 12.])\n",
      "tensor([ 8, 10, 12])\n",
      "tensor([ 8, 10, 12])\n",
      "tensor([1., 2., 3.])\n",
      "tensor([2., 4., 6.])\n",
      "tensor([False, False, False])\n"
     ]
    }
   ],
   "source": [
    "# Tensor math and comparison operations \n",
    "x = torch.tensor([1,2,3])\n",
    "y = torch.tensor([7,8,9])\n",
    "z1 = torch.empty(3)\n",
    "torch.add(x,y,out=z1)\n",
    "z3 = torch.add(x,y)\n",
    "print(z1)\n",
    "z2 = x+y\n",
    "print(z2)\n",
    "print(z3)\n",
    "\n",
    "# division \n",
    "z = torch.true_divide(x,y)  # This is element wise division\n",
    "\n",
    "# Any operation with underscore is done IN PLACE!\n",
    "\n",
    "t = torch.zeros(3)\n",
    "t.add_(x)\n",
    "print(t)\n",
    "t += x \n",
    "print(t)\n",
    "\n",
    "# Exponentiation \n",
    "z = x.pow(2)\n",
    "z= x**2 \n",
    "\n",
    "# comparison \n",
    "z = x==0\n",
    "print(z)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8896, 1.1292, 1.3298],\n",
      "        [1.1706, 1.5681, 1.5771]])\n",
      "tensor([[0.8896, 1.1292, 1.3298],\n",
      "        [1.1706, 1.5681, 1.5771]])\n",
      "tensor([[0.2722, 0.2976, 0.1309],\n",
      "        [0.6837, 0.7476, 0.3288],\n",
      "        [0.7154, 0.7822, 0.3440]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# matrix multiplication \n",
    "x1 = torch.rand((2,5))\n",
    "x2 = torch.rand((5,3))\n",
    "x3 = torch.mm(x1,x2)\n",
    "print(x3)\n",
    "x3 = x1.mm(x2)\n",
    "print(x3)\n",
    "x1 = torch.rand((1,3))\n",
    "x2 = torch.rand((1,3))\n",
    "x3 = torch.mm(x1.T,x2)\n",
    "print(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.0162, 5.0553, 2.5448, 3.7527, 5.3403],\n",
      "        [5.6035, 5.5995, 2.6677, 4.0188, 5.9529],\n",
      "        [4.1743, 4.2291, 2.0880, 3.0697, 4.4278],\n",
      "        [5.8484, 5.8907, 2.8990, 4.2977, 6.2142],\n",
      "        [5.3669, 5.6551, 3.1726, 4.3755, 5.6893]])\n"
     ]
    }
   ],
   "source": [
    "# Matrix exponentiation \n",
    "matrix_exp = torch.rand(5,5)\n",
    "print(matrix_exp.matrix_power(3)) # matrix multiplication by itself a few times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0446, 0.6909, 0.3626])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# elementwise multiplication \n",
    "x = torch.rand(3)\n",
    "y = torch.rand(3)\n",
    "z = x*y \n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0982)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dot product \n",
    "z = torch.dot(x,y)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match matrix multiplication \n",
    "batch = 32\n",
    "n = 10 \n",
    "m = 20 \n",
    "p = 30 \n",
    "\n",
    "tensor1 = torch.rand((batch,n,m))\n",
    "tensor2 = torch.rand((batch,m,p))\n",
    "out_bmm = torch.bmm(tensor1, tensor2) # (batch, n,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0684, -0.0601,  0.2423, -0.0154, -0.5769],\n",
      "        [-0.3708, -0.7928, -0.7123, -0.5806, -0.5480],\n",
      "        [-0.7302, -0.1437,  0.0606, -0.3663, -0.1901],\n",
      "        [-0.7819, -0.5372, -0.2434,  0.0524, -0.7538],\n",
      "        [-0.5705, -0.3558,  0.1575, -0.2604, -0.0439]])\n",
      "tensor([[0.8931, 0.8651, 0.9904, 0.7470, 0.3373],\n",
      "        [0.5998, 0.1448, 0.0782, 0.1842, 0.3668],\n",
      "        [0.2417, 0.7874, 0.8512, 0.4440, 0.7080],\n",
      "        [0.1887, 0.4095, 0.5981, 0.7979, 0.1446],\n",
      "        [0.4026, 0.5865, 0.9264, 0.5445, 0.8391]])\n"
     ]
    }
   ],
   "source": [
    "# Example of broadcasting \n",
    "x1 = torch.rand((5,5))\n",
    "x2 = torch.rand((1,5))   # This will be expanded to match the shape of x1 \n",
    "z = x1 - x2\n",
    "print(z)\n",
    "\n",
    "z = x1**x2 # elementwise power\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.1077, 3.1104, 2.2867])\n",
      "tensor([0.8493, 0.7476, 0.8170, 0.4640, 0.9809])\n",
      "tensor([0, 2, 1, 0, 1])\n",
      "tensor([0, 4, 4])\n",
      "tensor(0.5003)\n",
      "tensor([[0.0900, 0.1898, 0.1582, 0.3424, 0.3756],\n",
      "        [0.6980, 0.2601, 0.1587, 0.4248, 0.9485],\n",
      "        [0.8493, 0.7476, 0.8170, 0.4640, 0.9809]])\n",
      "tensor([[0.8493, 0.8000, 0.8000, 0.8000, 0.8000],\n",
      "        [0.8000, 0.8000, 0.8170, 0.8000, 0.9809],\n",
      "        [0.8000, 0.8000, 0.8000, 0.8000, 0.9485]])\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "# Other tensor operations\n",
    "x = torch.rand(3,5)\n",
    "sum_x = torch.sum(x,dim=1)\n",
    "print(sum_x)\n",
    "values, indices = torch.max(x,dim=0)\n",
    "print(values)\n",
    "print(indices)\n",
    "z = torch.argmax(x,dim =1)\n",
    "print(z)\n",
    "z = torch.mean(x.float())\n",
    "print(z)\n",
    "sorted_y, indices = torch.sort(x,dim =0,descending =False)\n",
    "print(sorted_y)\n",
    "z = torch.clamp(x,min=0.8)\n",
    "print(z)\n",
    "x = torch.tensor([1,0,1,1,1],dtype = torch.bool)\n",
    "z = torch.any(x)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25])\n",
      "tensor([], dtype=torch.int64)\n",
      "tensor([ 4,  6,  8, 10, 12, 14])\n",
      "(tensor([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12]),)\n",
      "3\n",
      "tensor([0.0026, 0.0056, 0.0114, 0.0142, 0.0223, 0.0274, 0.0432, 0.0553, 0.0681,\n",
      "        0.1172, 0.1242, 0.1502, 0.1643, 0.1693, 0.2334, 0.2444, 0.2539, 0.2869,\n",
      "        0.2932, 0.2939, 0.3152, 0.3471, 0.3814, 0.3889, 0.4149, 0.4276, 0.4502,\n",
      "        0.4852, 0.4918, 0.4992, 0.5042, 0.5078, 0.5399, 0.5444, 0.5470, 0.5478,\n",
      "        0.5829, 0.5848, 0.6143, 0.6389, 0.7001, 0.7096, 0.7144, 0.7321, 0.7548,\n",
      "        0.7687, 0.7753, 0.7844, 0.8216, 0.8401, 0.8430, 0.8431, 0.8676, 0.8770,\n",
      "        0.8852, 0.9510, 0.9657, 0.9675, 0.9897, 0.9966])\n",
      "torch.Size([60])\n"
     ]
    }
   ],
   "source": [
    "## Tensor indexing \n",
    "batch_size = 10 \n",
    "features = 25 \n",
    "x=torch.rand((batch_size,features))\n",
    "print(x[0].shape)\n",
    "\n",
    "x = torch.arange(3,16)\n",
    "print(x[(x<2) & (x>8)])\n",
    "print(x[x.remainder(2)==0])\n",
    "print(torch.where(x>5))\n",
    "\n",
    "y = torch.rand(3,4,5)\n",
    "print(y.ndimension())\n",
    "print(y.unique())\n",
    "print(y.unique().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "tensor([[0, 3, 6],\n",
      "        [1, 4, 7],\n",
      "        [2, 5, 8]])\n"
     ]
    }
   ],
   "source": [
    "# tensor reshaping \n",
    "\n",
    "x = torch.arange(9)\n",
    "x33 = x.view(3,3)   # Acts on continuous tensors. Tensors which are stored in continuous blocks in memory.\n",
    "print(x33)\n",
    "x33 = x.reshape(3,3)\n",
    "print(x33.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5])\n",
      "torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.rand(2,5)\n",
    "x2 = torch.rand(2,5)\n",
    "print(torch.cat((x1,x2),dim=0).shape)\n",
    "print(torch.cat((x1,x2),dim=1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 60])\n",
      "torch.Size([64, 6, 2, 5])\n"
     ]
    }
   ],
   "source": [
    "batch = 64\n",
    "x = torch.rand((batch,2,5,6))\n",
    "z = x.view(batch,-1)\n",
    "print(z.shape)\n",
    "z = x.permute(0,3,1,2)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 1])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(10)\n",
    "print(x.unsqueeze(1).unsqueeze(0).shape)\n",
    "print(x.unsqueeze(1).squeeze(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivatives \n",
    "\n",
    "What makes Pytorch really nice is its ability to process derivatives with respect to the tensors that ahve requires_grad set to true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([275.0395], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(10,dtype=torch.float)/2\n",
    "w = torch.arange(10,dtype=torch.float,requires_grad= True)/3\n",
    "b = torch.rand(1, requires_grad= True)\n",
    "l = torch.rand(10)\n",
    "\n",
    "y = w.dot(x)*l.dot(l) + b\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward() # This computes the derivatives! \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx: None\n",
      "dy/dw: None\n",
      "dy/db: tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\andy cai\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(\"dy/dx:\", x.grad)\n",
    "print(\"dy/dw:\", w.grad)\n",
    "print(\"dy/db:\", b.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.array([[73,67,43],\n",
    "                   [91,88,64],\n",
    "                   [87,134,58],\n",
    "                   [102,43,37],\n",
    "                   [69,96,70]],dtype = 'float32')\n",
    "targets = np.array([[56,70],\n",
    "                  [81,101],\n",
    "                    [119,133],\n",
    "                    [22,37],\n",
    "                    [103,119]],dtype = 'float32')\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "w = torch.randn(2,3,requires_grad=True)\n",
    "b = torch.randn(2,requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[161.7383,  -6.7699],\n",
      "        [215.1136,  -4.4106],\n",
      "        [214.4779,  15.9850],\n",
      "        [184.9184, -36.0167],\n",
      "        [196.6936,  13.8238]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def model(x):\n",
    "    return x @ w.T + b\n",
    "\n",
    "\n",
    "def mse(preds, targets):\n",
    "    diff = targets - preds\n",
    "    return torch.sum(diff*diff)/diff.numel()\n",
    "# This is the prediction from the model in the untrained state! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[161.7383,  -6.7699],\n",
      "        [215.1136,  -4.4106],\n",
      "        [214.4779,  15.9850],\n",
      "        [184.9184, -36.0167],\n",
      "        [196.6936,  13.8238]], grad_fn=<AddBackward0>)\n",
      "tensor(12069.4941, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "preds = model(inputs)\n",
    "print(preds)\n",
    "loss = mse(preds,targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute gradients\n",
    "we can automatically compute the gradient of the loss with all the different tensors! \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()  #computes it !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10262.4697,  9536.1152,  6250.8540],\n",
      "        [-8016.3452, -8667.2715, -5379.6401]])\n",
      "tensor([118.3884, -95.4777])\n"
     ]
    }
   ],
   "source": [
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0.])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.grad.zero_() # The reson for this is because pytorch accumulates gradients. The next time we call backwards the gradient is \n",
    "# added. \n",
    "b.grad.zero_()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use gradient descent\n",
    "\n",
    "The following steps are required: \n",
    "1. Generate predictions \n",
    "2. calculate the loss\n",
    "3. compute the gradients wrt to the weights and biases\n",
    "4. adjust weights by subtracting stepsize*gradient \n",
    "5. reset the gradients to 0 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(inputs)\n",
    "\n",
    "loss = mse(preds,targets)\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad(): \n",
    "    w-= w.grad* 1e-5\n",
    "    b -= b.grad*1e-5\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few points to note: \n",
    "    * We use `torch.no_grad` to indicate that we dont track, calculate or modify gradients while updating the weights and biases. \n",
    "    * we are using a small update step.\n",
    "    * set the gradient back to 0 so that future calculations are not affected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "w = torch.randn(2,3,requires_grad=True)\n",
    "b = torch.randn(2,requires_grad=True)\n",
    "for i in range(1000):\n",
    "    preds = model(inputs)\n",
    "    loss = mse(preds, targets)\n",
    "    loss.backward()\n",
    "    with torch.no_grad(): \n",
    "        w-= w.grad* 2e-5\n",
    "        b -= b.grad*2e-5\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "    errors.append(float(loss.detach().numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x28f4d9490f0>]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.plot(np.log(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9609705209732056\n"
     ]
    }
   ],
   "source": [
    "print(errors[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network!\n",
    "\n",
    "Often data has millions of rows, which we cant fit into memory. Matric multiplication is slow. O(N3). Good to work with smaller matrices. This is batch training! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# Input (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43], [91, 88, 64], [87, 134, 58], \n",
    "                   [102, 43, 37], [69, 96, 70], [73, 67, 43], \n",
    "                   [91, 88, 64], [87, 134, 58], [102, 43, 37], \n",
    "                   [69, 96, 70], [73, 67, 43], [91, 88, 64], \n",
    "                   [87, 134, 58], [102, 43, 37], [69, 96, 70]], \n",
    "                  dtype='float32')\n",
    "\n",
    "# Targets (apples, oranges)\n",
    "targets = np.array([[56, 70], [81, 101], [119, 133], \n",
    "                    [22, 37], [103, 119], [56, 70], \n",
    "                    [81, 101], [119, 133], [22, 37], \n",
    "                    [103, 119], [56, 70], [81, 101], \n",
    "                    [119, 133], [22, 37], [103, 119]], \n",
    "                   dtype='float32')\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and DataLoader \n",
    "A dataset allows access to rows from inputs and targets as tuples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 91.,  88.,  64.],\n",
       "         [102.,  43.,  37.],\n",
       "         [ 73.,  67.,  43.],\n",
       "         [ 87., 134.,  58.]]), tensor([[ 81., 101.],\n",
       "         [ 22.,  37.],\n",
       "         [ 56.,  70.],\n",
       "         [119., 133.]]))"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset \n",
    "train_ds = TensorDataset(inputs,targets)\n",
    "train_ds[[1,3,5,7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch:\n",
      "batch:\n",
      "batch:\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 5 \n",
    "train_dl = DataLoader(train_ds, batch_size,shuffle= True)\n",
    "\n",
    "for xb, yb in train_dl:\n",
    "    print(\"batch:\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.linear \n",
    "\n",
    "This creates a model, initialises wweights and biases automatically.  define the model using `nn.linear` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.1083, -0.3360, -0.4275],\n",
      "        [ 0.5521, -0.1228, -0.0344]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0301, -0.1235], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Linear(3,2) #3 inputs, 2 outputs\n",
    "print(model.weight)\n",
    "print(model.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(inputs)\n",
    "#print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F \n",
    "# Define loss function: \n",
    "loss_fn = F.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10862.8242, grad_fn=<MseLossBackward>)\n",
      "tensor(10862.8242, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = loss_fn(preds, targets)\n",
    "print(loss)\n",
    "loss = mse(preds,targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer \n",
    "Instaed of manually manipulating the model's weights and biases using gradients, we can use the optimizer optim.SGD ` stochastic gradient descent` Samples are selected randomly in batches to perfor estimation of the objective function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer \n",
    "opt = torch.optim.SGD(model.parameters(),lr = 1e-5) # You can tell it what we are updating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(num_epochs, model, loss_fn, opt):\n",
    "    # repeat for given number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # train with batches of data \n",
    "        for xb,yb in train_dl:\n",
    "            # 1. generate predictions \n",
    "            preds = model(xb)\n",
    "            \n",
    "            # 2. Calculate the loss \n",
    "            loss = loss_fn(preds, yb)\n",
    "            \n",
    "            # 3. compute the gradients \n",
    "            loss.backward()\n",
    "            \n",
    "            # 4. Update parameters using gradients \n",
    "            opt.step()\n",
    "            \n",
    "            # 5. reset the gradient to 0 \n",
    "            opt.zero_grad()\n",
    "            \n",
    "            \n",
    "        #print progress \n",
    "        if (epoch+1) %10 ==0: \n",
    "            print(\"epoch %d / %d , loss = %.4f\" %(epoch+1, num_epochs, loss))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 / 100 , loss = 3.6932\n",
      "epoch 20 / 100 , loss = 14.6340\n",
      "epoch 30 / 100 , loss = 12.7535\n",
      "epoch 40 / 100 , loss = 8.8777\n",
      "epoch 50 / 100 , loss = 15.6925\n",
      "epoch 60 / 100 , loss = 10.8409\n",
      "epoch 70 / 100 , loss = 16.7094\n",
      "epoch 80 / 100 , loss = 5.6360\n",
      "epoch 90 / 100 , loss = 17.3870\n",
      "epoch 100 / 100 , loss = 11.9532\n"
     ]
    }
   ],
   "source": [
    "fit(100,model, loss_fn, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
